# config.yaml

model:
  class_path: lib.training.modules.DenoisingDiffusionModule
  init_args:
    model:
      class_path: model.RibonucleicAcidSE3Transformer
      init_args:
        atom_embedding_dim: 12
        timestep_embedding_dim: 4
        num_timesteps: 1000
        num_layers: 6
        num_heads: 8
        num_atom_types: 4
        k_nearest_neighbors: 25
    objective:
      class_path: loss.KabschLoss
    diffused_variable: coordinate

data:
  class_path: lib.data.datamodules.netCDFDataModule
  init_args:
    train_paths : 
      - data/train
    validate_paths : 
      - data/val
    batch_size: 1
    input_variables:
      - sequence
      - coordinate


trainer:
  gradient_clip_val: 1.0
  max_epochs: 50
  devices: 1
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      save_dir: ./logs/
      log_model: all
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        filename: best_model
        mode: min
        save_top_k: 1
        save_last: true
        dirpath: ./checkpoints/


optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.001